{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byrcewang/fine-tuning_every_llm/blob/main/Fine_tuning_nous_hermes2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick fine-tuning of LLMs with Gradient.AI\n",
        "## Sourceï¼š https://www.youtube.com/watch?v=74NSDMvYZ9Y"
      ],
      "metadata": {
        "id": "giHISM6e8bjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gradientai --upgrade\n",
        "import os\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = \"YOUR_TOKEN\"\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = \"YOUR_WORKSPACE_ID\""
      ],
      "metadata": {
        "id": "U02ytLrPA2rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "\n",
        "def main():\n",
        "  with Gradient() as gradient:\n",
        "      base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "      new_model_adapter = base_model.create_model_adapter(\n",
        "          name=\"test model 3\"\n",
        "      )\n",
        "      print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "      sample_query = \"### Instruction: Who is Matthew Berman? \\n\\n### Response:\"\n",
        "      print(f\"Asking: {sample_query}\")\n",
        "\n",
        "      # before fine-tuning\n",
        "      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "      print(f\"Generated (before fine-tune): {completion}\")\n",
        "\n",
        "      samples = [\n",
        "        { \"inputs\": \"### Instruction: Who is Matthew Berman? \\n\\n### Response: Matthew Berman is a popular video creator who talks about AI\" },\n",
        "        { \"inputs\": \"### Instruction: Who is the person named Matthew Berman ? \\n\\n### Response: Matthew Berman is a YouTuber who talks about AI\" },\n",
        "        { \"inputs\": \"### Instruction: Can you tell me about Matthew Berman? \\n\\n### Response: Matthew Berman is a popular creator who specializes in AI content\" },\n",
        "      ]\n",
        "\n",
        "      # this is where fine-tuning happens\n",
        "      # num_epochs is the number of times you fine-tune the model\n",
        "      # more epochs tends to get better results, but you also run the risk of \"overfitting\"\n",
        "      # play around with this number to find what works best for you\n",
        "      num_epochs = 3\n",
        "      count = 0\n",
        "      while count < num_epochs:\n",
        "          print(f\"Fine-tuning the model, iteration {count + 1}\")\n",
        "          new_model_adapter.fine_tune(samples=samples)\n",
        "          count = count + 1\n",
        "\n",
        "      # after fine-tuning\n",
        "      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "      print(f\"Generated (after fine-tune): {completion}\")\n",
        "\n",
        "      new_model_adapter.delete()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Scor9o08VVhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With comments and explanations\n",
        "\n",
        "# Import the Gradient library, which is used to interact with the Gradient platform.\n",
        "from gradientai import Gradient\n",
        "\n",
        "# Define the main function, the entry point of the program.\n",
        "def main():\n",
        "    # Create a context for using the Gradient platform.\n",
        "    with Gradient() as gradient:\n",
        "        # Get a base model named \"nous-hermes2\" from the Gradient platform.\n",
        "        base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "        # Create a new model adapter and give it the name \"test model 3\".\n",
        "        new_model_adapter = base_model.create_model_adapter(\n",
        "            name=\"test model 3\"\n",
        "        )\n",
        "\n",
        "        # Print a message indicating that a model adapter has been created and display its ID.\n",
        "        print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "        # Define a sample query, which contains an instruction about Matthew Berman.\n",
        "        sample_query = \"### Instruction: Who is Matthew Berman? \\n\\n### Response:\"\n",
        "\n",
        "        # Print a message indicating the question being asked in the sample query.\n",
        "        print(f\"Asking: {sample_query}\")\n",
        "\n",
        "        # Generate text completion for the sample query before fine-tuning the model.\n",
        "        completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "\n",
        "        # Print the generated text before fine-tuning.\n",
        "        print(f\"Generated (before fine-tune): {completion}\")\n",
        "\n",
        "        # Define a list of samples, each containing inputs and responses.\n",
        "        samples = [\n",
        "            { \"inputs\": \"### Instruction: Who is Matthew Berman? \\n\\n### Response: Matthew Berman is a popular video creator who talks about AI\" },\n",
        "            { \"inputs\": \"### Instruction: Who is the person named Matthew Berman ? \\n\\n### Response: Matthew Berman is a YouTuber who talks about AI\" },\n",
        "            { \"inputs\": \"### Instruction: Can you tell me about Matthew Berman? \\n\\n### Response: Matthew Berman is a popular creator who specializes in AI content\" },\n",
        "        ]\n",
        "\n",
        "        # This is where the fine-tuning of the model happens.\n",
        "        # num_epochs represents the number of times the model will be fine-tuned.\n",
        "        # More epochs often lead to better results, but there's a risk of \"overfitting,\"\n",
        "        # so you can experiment with this number to find the best value.\n",
        "        num_epochs = 3\n",
        "        count = 0\n",
        "        while count < num_epochs:\n",
        "            print(f\"Fine-tuning the model, iteration {count + 1}\")\n",
        "            # Fine-tune the model using the defined samples.\n",
        "            new_model_adapter.fine_tune(samples=samples)\n",
        "            count = count + 1\n",
        "\n",
        "        # Generate text completion for the sample query after fine-tuning the model.\n",
        "        completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "\n",
        "        # Print the generated text after fine-tuning.\n",
        "        print(f\"Generated (after fine-tune): {completion}\")\n",
        "\n",
        "        # Delete the new model adapter to clean up resources.\n",
        "        new_model_adapter.delete()\n",
        "\n",
        "# Check if the script is being run as the main program.\n",
        "if __name__ == \"__main__\":\n",
        "    # Call the main function if the script is executed as the main program.\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ar5-X9V89Lse"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}